---
title: "Master en Big Data. Fundamentos Matemáticos del Análisis de Datos (FMAD)."
author: "Gutiérrez García, Laura"
date: 'Curso 2021-22. Última actualización: `r format(Sys.time(), "%Y-%m-%d")`'
output:
  word_document: default
  html_document: default
  pdf_document: default
subtitle: Tarea 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Librerías


Antes de comenzar con la práctica, cargamos todas las librerías necesarias:

```{r, message=FALSE}
library(tidyverse) # Uso de dplyr y ggplot
library(gridExtra) # Mostrar varios gráficos juntos
library(nycflights13) # Base de datos Ejercicio 3
```

# Instrucciones preliminares

+ Empieza abriendo el proyecto de RStudio correspondiente a tu repositorio personal de la asignatura. 

+ En todas las tareas tendrás que repetir un proceso como el descrito en la sección *Repite los pasos Creando un fichero Rmarkdown para esta práctica* de la *Práctica00*. Puedes releer la sección *Practicando la entrega de las Tareas* de esa misma práctica para recordar el procedimiento de entrega.

# Ejercicio 0

+ Si no has hecho los *Ejercicios* de la *Práctica00* (págs. 12 y 13) hazlos ahora y añádelos a esta tarea. Si ya los has hecho y entregado a través de GitHub no hace falta que hagas nada.

# Ejercicio 1. Análisis exploratorio de un conjunto de datos y operaciones con dplyr. 

+ Vamos a utilizar el conjunto de datos contenido en el fichero (es un enlace):  
[cholesterol.csv](https://gist.githubusercontent.com/fsansegundo/ee991e53e1a571dd34034c42b5516eae/raw/2206455b5772e90c5a2a24a3f42a84408fd1d1c5/cholesterol.csv)  
Los datos proceden de un estudio realizado en la *University of Virginia School of Medicine* que investiga la prevalencia de la obesidad, la diabetes y otros factores de riesgo cardiovascular. Se puede encontrar más información sobre el fichero en este enlace:  
[https://biostat.app.vumc.org/wiki/pub/Main/DataSets/diabetes.html](https://biostat.app.vumc.org/wiki/pub/Main/DataSets/diabetes.html)  

+ Carga el conjunto de datos en un data.frame de R llamado `chlstrl`.

Leemos el conjunto de datos con la función read_csv de la librería tidyverse y mostramos el contenido de las 6 primeras filas:

```{r, message=FALSE}
chlstrl <- read_csv("./data/cholesterol.csv")
head(chlstrl)
```


+ Empezaremos por información básica sobre el conjunto de datos. Cuántas observaciones contiene, cuáles son las variables y de qué tipos,...


Número de observaciones y variables:
```{r}
nrow(chlstrl) # Nº filas = nº observaciones
ncol(chlstrl) # Nº columnas = nº variables
dim(chlstrl) # Nº filas x nº columnas

```
Cuáles son las variables:
```{r}
names(chlstrl)
str(chlstrl)
```
Con la función "names" vemos el nombre de las variables del conjunto de datos y con la función "str" se indica el tipo de dato que almacenan dichas variables. En nuestro caso, todas son numéricas salvo el sexo que es de tipo carácter.



+ Asegúrate de comprobar si hay datos ausentes y localízalos en la tabla. 

```{r}
head(is.na(chlstrl))
head(complete.cases(chlstrl))
summary(chlstrl)
```
Con la función "is.na" devuelve un dataframe con los valores lógicos True/False indicando dónde se encuentran los datos faltantes.
Por otra parte, la función "complete.cases" nos indica si en la fila hay algún dato faltante o no (True si la fila está completa y False si hay algún missing) y la función summary, además de informarnos sobre los descriptivos de cada variable (mínimo, máximo, cuartiles y media) también nos indica el número de dadtos faltantes en cada una de ellas.

Si quisiéramos seleccionar las filas donde no hay ningún dato faltante:

```{r}
chlstrl[complete.cases(chlstrl),]

```
Sin embargo, a pesar del escaso número de estos datos faltantes, como depende de cada variable de estudio, se tratarán de acuerdo a la característica que se esté analizando incluyendo como argumento na.rm = T en las funciones de los ejercicios posteriores.



+ El análisis exploratorio (numérico y gráfico) debe cubrir todos los tipos de variable de la tabla. Es decir, que al menos debes estudiar una variable por cada tipo de variable presente en la tabla. El análisis debe contener, al menos:
  - Para las variables cuantitativas (continuas o discretas).  
    Resumen numérico básico.  
    Gráficas (las adecuadas, a ser posible más de un tipo de gráfico).  
  - Variables categóricas (factores).  
    Tablas de frecuencia (absolutas y relativas).  
    Gráficas (diagrama de barras).  
    
Análisis exploratorio para la variable cuantitativa colesterol ("chol"):
```{r}
summary(chlstrl$chol)

# Recorrido intercuartílico
IQR(chlstrl$chol, na.rm = T)

# Valores atípicos
unname(quantile(chlstrl$chol, probs = c(1/4, 3/4), na.rm = T) + c(-1, 1) * 1.5 * IQR(chlstrl$chol, na.rm = T))

```
Mediante el resumen de esta variable, se observa que los valores para el colesterol oscilan entre un mínimo de 78 y un máximo de 443 obteniendo un nivel medio de 207.8. El primer cuartil nos indica que el 25% de los datos se encuentra por debajo de un nivel de 179, la mediana que el 50% de los pacientes ha tenido unos niveles superiores a 204 y el tercer cuartil que el 75% de los pacientes tiene un nivel inferior a 230. Por otro lado, en esta variable solo hay un dato ausente (NA).

Continuando con el recorrido intercuartílico, con él se puede estudiar la dispersión (a partir de la diferencia entre el tercer y el primer cuartil), de tal forma que, cuánto mayor sea su valor, mayor es la dispersión.

En cuanto a los valores atípicos,se definen como aquellos que estarán fuera del rango (102.5,306.5).

A continuación, se realiza el histograma con la curva de densidad:

```{r, message = FALSE}
ggplot(chlstrl, aes(x = chol)) + 
  geom_histogram(aes(y=stat(density)), 
                  fill = "orange", color="black")  + 
  geom_density(color="red", size=1.5)
```

En el histograma se aprecia como el nivel de colesterol se asemeja a una distribución Normal con una cola alargada hacia la derecha (asimétrica por la derecha).

Ahora, vamos a representar los valores mediante un diagrama de cajas (boxplot) y un violinplot:

```{r, message = FALSE}
# Boxplot
ggplot(chlstrl) +
geom_boxplot(mapping = aes(y = chol), fill="orange")

# Violinplot
ggplot(chlstrl) +
geom_violin(mapping = aes(x=0, y = chol)) +
scale_x_discrete(breaks = c()) +
geom_boxplot(mapping = aes(y = chol), fill="green") +
geom_jitter(aes(x=0, y = chol),
position = position_jitter(w=0.05, h= 0), col="blue")
```

Como ya se describió en el resumen numérico, la media de los valores se encuentra en torno a los 200 y hay ciertos outliers que sobresalen del recorrido intercuartílico convirtiéndose en valores extremos (por debajo de 100 y encima de 300).

Otras medidas de dispersión son:

- Desviación absoluta mediana

```{r}

mad(chlstrl$chol, na.rm = TRUE)

```

- Varianza y desviación típica muestrales

```{r}

var(chlstrl$chol, na.rm = TRUE) # Varianza
sd(chlstrl$chol, na.rm = TRUE) # Desviación típica

```



Análisis exploratorio para la variable categórica : sexo ("gender")

Tablas de frecuencia (absolutas y relativas).

- Frecuencias absolutas:

```{r}
chlstrl %>% 
  count(gender)
```
- Frecuencias relativas:

```{r}
 chlstrl %>% 
    count(gender) %>%
      mutate(gender, relFreq = prop.table(n), n=NULL)
```
El 58% de los pacientes son mujeres y el 42% hombres.

- Diagrama de barras con la frecuencia absoluta: 

```{r}
ggplot(chlstrl) +
geom_bar(mapping = aes(x = gender, fill=gender))
```


+ Los valores de `height` y `weight` están en pulgadas (inches) y libras (pounds) respectivamente. Una libra son $\approx$ 0.454kg y una pulgada son $\approx$ 0.0254m.  Usa dplyr para convertir esas columnas a metros y kilogramos respectivamente.  Las nuevas columnas deben llamarse igual que las originales. 

Hago el cambio con las variables altura y peso y lo guardo en otro dataframe para no sobrescribir los cambios en la base de datos original:

```{r}
chlstrl2 <- chlstrl %>% 
              mutate(height = height*0.0254,
                     weight = weight*0.454) 
```


+ Ahora usa esos valores de `height` y `weight` para añadir una nueva columna llamada BMI, definida mediante:
$$BMI = \dfrac{weight}{height^2}$$
(se divide por el cuadrado de la altura). 

Se añade la nueva columna denomida como BMI al dataframe y mostramos las 6 primeras filas del conjunto de datos resultante:

```{r}

chlstrl2 <- chlstrl2 %>% 
              mutate(BMI = weight/height^2)

head(chlstrl2)

```


+ Crea una nueva columna llamada `ageGroup` dividiendo la edad en los siguientes tres niveles:
  ```{r echo=FALSE, comment=NULL}
  cat("(10,40], (40,70], (70,100]")
  ```
  
```{r}

chlstrl2 <- chlstrl2 %>% 
              mutate(ageGroup = cut(age, breaks = c(10, 40, 70, 100) ))

head(chlstrl2)

```

+ Usando `dplyr` calcula cuántas observaciones hay en cada nivel de `ageGroup` (indicación: usa `group_by`).

```{r}
chlstrl2 %>% 
  group_by(ageGroup) %>% 
  count(ageGroup)

```
El grupo de 40 a 70 años es el que más observaciones tiene (207).

Ahora, usando aquellas observaciones que corresponden a mujeres, ¿cuál es la media del nivel de colesterol y de BMI en cada uno de esos grupos de edad?

Filtrando por las filas de sexo femenino y agrupando por el grupo de edad, se calculan las medias para las variables "chol" y "BMI":

```{r}
chlstrl2 %>% 
  filter(gender=="female") %>% 
  group_by(ageGroup) %>% 
  summarise(chol.mean = mean(chol, na.rm = T),
            BMI.mean = mean(BMI, na.rm = T))
```


# Ejercicio 2: Funciones de R.

+ Crea una función de R llamada `cambiosSigno` que dado un vector `x` de números enteros no nulos, como 
    ```{r echo=FALSE, comment=NULL}
    set.seed(2019)
    x = sample(c(-1, 1), 9, replace = TRUE) * sample(1:20, 9, replace = TRUE)
    cat(paste0(x, sep=", "))
    ```
calcule cuántos cambios de signo ha habido. Es decir, cuántas veces el signo de un elemento es distinto del signo del elemento previo. Por ejemplo, en el vector anterior hay 4 cambios de signo (en las posiciones 3, 4, 7 y 8). 
      
Para construir la función, primeramente se crea el vector lógico signo que almacena True si el número es positivo y False si es negativo. Como los vectores lógicos se tratan en R como 1 y 0, se le puede aplicar la función diff que calcula la diferencia entre las posiciones consecutivas de un vector. Así, si hacemos el valor absoluto de este resultado y lo sumamos, obtendremos el número de cambios de signo que ha habido.

Por otro lado, a la función se le incluye como argumento la generación de un vector aleatorio para que, en caso de no introducir ningún vector, se genere uno por defecto. Como resultado, la función devuelve una lista con el vector introducido (o generado) y el número de cambios de signo:
    
```{r}
cambiosSigno <- function(x=sample(c(-1, 1), 9, replace = TRUE) * sample(1:20, 9, replace = TRUE)){
  sol <- list()
  sol$vector <- x
  signo <- x>0
  sol$cambios <- sum(abs(diff(signo)))
  return(sol)
}

```


+ Modifica la función para que devuelva como resultado las posiciones donde hay cambios de signo. Llama `cambiosSignoPos(x)` a esa otra función. Por ejemplo, para el vector anterior el resultado de esta función sería
    ```{r echo=FALSE, results='asis'}
    cat("[1] 3 4 7 8")
    ```
    
Al igual que antes, la función, devuelve una lista con el vector introducido (o generado) y, en este caso, las posiciones donde se ha producido el cambio de signo:
    
```{r}
cambiosSignoPos <- function(x = sample(c(-1, 1), 9, replace = TRUE) * sample(1:20, 9, replace = TRUE)){
  sol <- list()
  sol$vector <- x
  signo <- x>0
  cambio <- c(0,abs(diff(signo)))
  sol$pos <- which(cambio==1)
  return(sol)
}
```
    
    También se valorará que incluyas en el código como usar `sample` para generar vectores aleatorios de 20 enteros *no nulos* (el vector debe poder tomar valores positivos y negativos).
    
Para comprobar el funcionamiento de las funciones se emplea el vector del ejemplo y se llama a la función sin argumento:

```{r}
set.seed(2019)
(x <-  sample(c(-1, 1), 9, replace = TRUE) * sample(1:20, 9, replace = TRUE))

cambiosSigno(x)

cambiosSignoPos(x)


# Sin pasar ningún argumento
cambiosSigno()
cambiosSignoPos()

```


# Ejercicio 3. R4DS.

Es recomendable que esta semana del curso  hagas al menos una lectura somera de los Capítulos 1 a 5 de [R for Data Science (R4DS), de H. Wickham](https://r4ds.had.co.nz/index.html), con énfasis especial en los Capítulos 3 y 5 (los capítulos 1, 2 y 4 son muy breves). Los siguientes apartados pretenden motivar esa lectura y por eso mismo pueden resultar un poco más laboriosos.  

+ Haz el [ejercicio 6 de la Sección 3.6.1 de R4DS](https://r4ds.had.co.nz/data-visualisation.html#exercises-3).

La base de datos a emplear en este ejercicio es "mpg" que podemos encontrar dentro de la librería tidyverse cargada al inicio.

- Gráficos:

```{r, message = FALSE}

g1 <- ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy)) +
      geom_smooth(mapping = aes(x = displ, y = hwy), se=FALSE)

g2 <- ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy)) +
      geom_smooth(mapping = aes(x = displ, y = hwy, group = drv), se= FALSE)

g3 <- ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy, color = drv)) +
      geom_smooth(mapping = aes(x = displ, y = hwy, group = drv, color = drv), se = FALSE)

g4 <- ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy, color = drv)) +
      geom_smooth(mapping = aes(x = displ, y = hwy), se = FALSE)

g5 <- ggplot(data = mpg) + 
      geom_point(mapping = aes(x = displ, y = hwy, color = drv)) +
      geom_smooth(mapping = aes(x = displ, y = hwy,group = drv, linetype = drv), se = FALSE)

g6 <- ggplot(data = mpg) +
      geom_point(aes(x = displ, y = hwy, fill=drv), shape = 21,color="white",size = 2, stroke = 2)

# Representación de todos los gráficos juntos
grid.arrange(g1,g2, g3, g4, g5, g6, nrow=3)
```


+ Haz el [ejercicio 1 de la Sección 5.2.4 de R4DS](https://r4ds.had.co.nz/transform.html#exercises-8). 

En este ejercicio, la base de datos a utilizar es flights:

```{r}
head(flights)
data("flights") # carga los datos en memoria
```


Find all flights that

1) Had an arrival delay of two or more hours

Como el retraso está registrado en minutos, se pasan las dos horas a minutos:

```{r}
filter(flights, arr_delay>=120)
```

2) Flew to Houston (IAH or HOU)

```{r}
filter(flights, dest=="IAH"|dest=="HOU")
# Otra forma:
# filter(flights, dest %in% c("IAH","HOU"))

```

3) Were operated by United, American, or Delta

```{r}
filter(flights,carrier=="UA"|carrier=="AA"|carrier=="DL")
# Otra forma:
# filter(flights, carrier %in% c("UA","AA","DL"))
```

4) Departed in summer (July, August, and September)

```{r}
filter(flights, month %in% c(7:9))
```

5) Arrived more than two hours late, but didn’t leave late

```{r}
filter(flights, arr_delay>120 & dep_delay <= 0)
```

6) Were delayed by at least an hour, but made up over 30 minutes in flight

```{r}
filter(flights, dep_delay >= 60, dep_delay - arr_delay > 30)
```


7) Departed between midnight and 6am (inclusive)

En primer lugar, vemos qué pinta tiene la variable dep_time para poder analizar de un modo correcto sus valores:

```{r}
summary(flights$dep_time)
```
El formato para la media noche es 24:00 y no 0:00, por lo que hay que tenerlo en cuenta a la hora de seleccionar las filas correspondientes al tiempo requerido

```{r}
filter(flights, dep_time <= 600 | dep_time == 2400)
```

